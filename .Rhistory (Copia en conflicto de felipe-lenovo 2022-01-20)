casen_seleccion <- select(casen_2017, pobreza_multi_5d, expr, expc, varstrat, region, comuna)
# Para guardar CASEN completa en formato RDS (habiendo cargado desde SPSS)
saveRDS(casen_2017, file = "datos/2-casen_2017.RDS")
# Guardar CASEN sólo con variables de interés para análisis en formato RDS
saveRDS(casen_seleccion, file = "datos/2-casen_pobreza.RDS")
casen_2017 <- readRDS("datos/2-casen.RDS") # Alternativa ante no lectura SPSS
# ---- 2. CÁLCULO INDICADOR POBREZA MULTIDIMENSIONAL: NIVEL MUESTRAL ----
table(casen_2017$pobreza_multi_5d) # 1 = 44.972 // Variable original, coincide con libro de códigos
casen_2017$pobreza_multi_5d <- as.factor(casen_2017$pobreza_multi_5d)
# ¿Nos sirve este valor para conocer la situación nacional?
# ---- 3. CÁLCULO INDICADOR POBREZA MULTIDIMENSIONAL: NIVEL POBLACIONAL ----
#DEFINIR MUESTRA COMPLEJA PARA DATOS DE NIVEL NACIONAL/REGIONAL
casen_pond <- casen_2017  %>% as_survey_design(ids = 1, strata = varstrat, weights = expr)
#Definir variables CASEN: expr (factor de expansión regional), varstrat (error estratos de varianza)
#Definir argmentos as_survey_desig: id (Formula or data frame specifying cluster ids from largest level to smallest level, ~0 or ~1 is a formula for no clusters),
#strata (Formula or vector specifying strata), weights (Formula or vector specifying sampling weights as an alternative to prob),
#CÁLCULO POBREZA MULTI5D NACIONAL
pobrezamulti <- casen_pond %>%
group_by(pobreza_multi_5d) %>%
summarize(frecuencias = survey_total(na.rm = T),
proporcion = survey_mean(vartype = "ci", level = 0.95, na.rm = TRUE),
n = unweighted(n())) # Variable original
# Pobres multidimensionales
# Estimación de punto ponderada 19,828% (*)- Intervalo de confianza --> Li: 19,607% - Ls: 20,048%
# (*) Coincide con Cifra expandida de pobres multidimensionales publicada por CASEN: 3.530.889
# Coincide número oficial con cálculo propio: tasa es 20,7 (total = pobres+no pobres) y absoluto 3.530.889
3530889/(3530889+13529811)
# DISEÑO MUESTRAL SIN INCORPORAR ERROR DE CADA ESTRATO
casen_pond2 <- casen_2017 %>% as_survey_design(ids = 1, weights = expr)
# Pobreza multidimensional: frecuencias expandidas + proporción ponderada + IC proporción NC-95% + n muestral
pobrezamulti2 <- casen_pond2 %>%
group_by(pobreza_multi_5d) %>%
summarize(frecuencias = survey_total(),
proporcion = survey_mean(vartype = "ci", level = 0.95, na.rm = TRUE),
n = unweighted(n()))
# Pobres multidimensionales
# Estimación de punto ponderada 19,828% (*)- Intervalo de confianza --> Li: 19,603% - Ls: 20,053%
### INTERVALOS CALCULADOS SON DIFERENTES
# ----- 4. CONSTRUIR BASE PARA UTILIZAR OFF LINE
casen_seleccion <- select(casen_2017, pobreza_multi_5d, expr, expc, varstrat, region, comuna)
# Para guardar CASEN completa en formato RDS (habiendo cargado desde SPSS)
saveRDS(casen_2017, file = "datos/2-casen_2017.RDS")
# Guardar CASEN sólo con variables de interés para análisis en formato RDS
saveRDS(casen_seleccion, file = "datos/2-casen_pobreza.RDS")
# Evaluar instalación y/o carga de paquetes
pacman::p_load(tidyverse, haven, car, labelled)
casen_santiago <- readRDS("datos/5-casen-santiago.RDS")
# ---- Recodificar variables para construir indicador común
# Ver tipo de objeto y categorías de variable comuna
class(casen_santiago$comuna)
table(casen_santiago$comuna)
# Transformación variable comuna desde SPSS a formato 'character'
casen_santiago <- mutate(casen_santiago,
comunaf = labelled::to_character(casen_santiago$comuna,
levels = "labels",
drop_unused_labels = T))
# Elminamos etiqueta de variable
var_label(casen_santiago$comunaf) <- NULL
# Verificamos tabla con etiquetas
table(casen_santiago$comunaf)
# Recodificación módulo "r7" CASEN
# sección R: Identidades, redes y participación
# módulo de preguntas r7: ¿Alguien en su hogar, conoce a una persona que...?
# 1. Sí, alguien fuera del hogar / 2. Sí, alguien dentro del hogar / 3. Ambas
# 4. No conoce / 9. No sabe
names(casen_santiago) # Detectar columnas de interés (2 a 12)
casen_santiago[,c(2:12)] # Observar columnas de interés
# ---- Recodificación sistemática variables de módulo "r"
# "mutuate_at" y "pipe" de "tidyverse" permite aplicar instrucciones encadenadas
# sobre varias variables
# Primero, se codifican como numérica todas las variables.
# Segundo, se recodifican sus valores dejando como 2 los valores "no" conoce/sabe
# Tercero, se eliminan todos los casos con NA dejando sólo a respondientes efectivos (jefes de hogar)
df2 <- casen_santiago %>%
mutate_at(vars(2:12), ~as.numeric(.)) %>%
mutate_at(vars(2:12), funs(car::recode(. ,"1:3=1;4:9=2"))) %>%
drop_na()
View(df2)
# ---- Reducir dimensionalidad calculando variables a nivel comuna.
# El sentido del código se aprecia analizando la primera línea del 'summarise'
# Esto todavía se podría automatizar más, pero implicaría programación funcional (¿otro curso?).
# Dimensionalidad se reduce, calculando cada variable como proporción de categoría de referencia
comunas <- df2 %>%
group_by(comunaf) %>%
summarise(enfermos = sum(cuidado_enfermos == "1")/sum(cuidado_enfermos),
dependientes = sum(ciudado_dependientes == "1")/sum(ciudado_dependientes),
vehiculo = sum(vehiculo == "1")/sum(vehiculo),
dinero = sum(dinero == "1")/sum(dinero),
tramites = sum(tramites == "1")/sum(tramites),
tecnologias = sum(tecnologias == "1")/sum(tecnologias),
reparaciones_hogar = sum(reparaciones_hogar == "1")/sum(reparaciones_hogar),
trabajo = sum(trabajo == "1")/sum(trabajo),
consejos = sum(consejos == "1")/sum(consejos),
idiomas = sum(idiomas == "1")/sum(idiomas),
estudios = sum(estudios == "1")/sum(estudios))
View(comunas)
# ---- 3. ANÁLISIS DE CONGLOMERADOS - MÉTODO JERÁRQUICO ----
#Se usará la distancia euclidea: hay más distancias (ver ?dist)
#Se usarán variables no estandarizadas pues ya están como % (columnas 2:12)
# Cálculo de distancias (euclídea al cuadrado) con todas las variables incluídas
d <- dist(comunas[c(2:12)])^2 # distancia euclídea al cuadrado (^2)
# Error posible (teórico): no tenemos una predefinición de por qué importa cada variable
# Mostrar matriz de distancia
print(d,digits=1)
## Creación del MODELO JERARQUICO: "hclust" --> Hierarquical Clustering
# hay más algoritmos: ver ?hclust -> centroid, single, ward.D, etc.
# Se crea un modelo indicando matriz de distancias y algoritmo de clasificación.
hc <- hclust(d, method= "ward.D") # hc = 'hirarchical clustering' (algoritmo aglomerativo)
# método de clasificación: "distancia de Ward"
# Resultado se guarda como objeto 'lista' en entorno
# RESULTADO 1: historial de conglomeración
historial <- data.frame(hc[2:1]) # extracción historial de conglomeración
write.csv2(historial, file ="resultados/5-historial_hc.csv")
# Salto de mayor relevancia parece estar en solución de 3
# Elementos negativos son casos no conglomerados hasta ese paso (detección de atípicos).
View(historial)
# RESULTADO 2: dendograma
plot(hc, labels=comunas$comunaf, main = "Dendograma método jerárquico",
xlab = "Comuna",
ylab = "Distancia")
# dendograma con grupos marcados
rect.hclust (hc, k=3, border="red")
# RESULTADO 3: extraer conglomerado de pertenencia
#Para extraer conglomerado de pertenencia
pertenencia_hc <- cutree(hc, k=3) #Corte de grupos "k"
# Tabla de cantidad de casos por conglomerado
table(pertenencia_hc)
# Agregar solución de 3 conglomerados como variable de clasificación en base
comunas <- mutate(comunas, hc_3 = pertenencia_hc)
names(comunas)
View(comunas)
## RESULTADO 4: perfiles variables conglomeración según comunas (medias)
hc <- comunas %>%
group_by(hc_3) %>%
summarise(enfermos = mean(enfermos),
dependientes = mean(dependientes),
vehiculo = mean(vehiculo),
dinero = mean(dinero),
tramites = mean(tramites),
tecnologias = mean(tecnologias),
reparaciones_hogar = mean(reparaciones_hogar),
trabajo = mean(trabajo),
consejos = mean(consejos),
idiomas = mean(idiomas),
estudios = mean(estudios))
# imprimir tabla de caracterización de variables
write.csv2(hc, file = "resultados/5-medias-variables-conglomeración-j.csv")
#Remover todo excepto "comunas" del entorno
# ---- 4. ANÁLISIS DE CONGLOMERADOS - MÉTODO NO JERÁRQUICO ----
## Creación del MODELO NO JERARQUICO:
#Algoritmo K-Means, es muy utilizado, hay otros
# nstart= escoge el mejor punto de partida(aleat)
#         *poner num elevado
# centers= cantidad de conglomerados k
# iter.max= iteraciones/ pasos
km<-kmeans(comunas[2:12], centers=3, iter.max = 10, nstart = 200)
#Ver todos los resultados
km
km$iter #cantidad de interaciones
km$size #tamaño conglomerados
km$centers #centros conglomerados finales
km$cluster #conglomerado de pertenencia por caso
pertenencia_nh <-cbind(comunas[1], km[1]) #tabla con conglomerad de pertencia y comunas
View(pertenencia_nh)
#Agregar solución no jerárquica como variable de clasificación.
comunas <- mutate(comunas, km_3 = km$cluster)
# Variables de conglomeración en modelo no jerárquico
nh <- comunas %>%
group_by(km_3) %>%
summarise(enfermos = mean(enfermos),
dependientes = mean(dependientes),
vehiculo = mean(vehiculo),
dinero = mean(dinero),
tramites = mean(tramites),
tecnologias = mean(tecnologias),
reparaciones_hogar = mean(reparaciones_hogar),
trabajo = mean(trabajo),
consejos = mean(consejos),
idiomas = mean(idiomas),
estudios = mean(estudios))
View(nh)
# Exportar resultados a planilla
write.csv2(nh, file = "resultados/5-medias-variables-conglomeración-nj.csv")
# ----- GUARDAR BASE DE DATOS CON VARIABLES DE CONGLOMERACIÓN
saveRDS(comunas, file = "datos/5-cluster_comunas_casen.rds")
# ---- Cargar base de Casen recortada
casen_santiago <- readRDS("datos/5-casen-santiago.rds")
# ---- Recodificar variables para construir indicador común
# Ver tipo de objeto y categorías de variable comuna
class(casen_santiago$comuna)
table(casen_santiago$comuna)
# Transformación variable comuna desde SPSS a formato 'character'
casen_santiago <- mutate(casen_santiago,
comunaf = labelled::to_character(casen_santiago$comuna,
levels = "labels",
drop_unused_labels = T))
# Elminamos etiqueta de variable
var_label(casen_santiago$comunaf) <- NULL
# Verificamos tabla con etiquetas
table(casen_santiago$comunaf)
# Recodificación módulo "r7" CASEN
# sección R: Identidades, redes y participación
# módulo de preguntas r7: ¿Alguien en su hogar, conoce a una persona que...?
# 1. Sí, alguien fuera del hogar / 2. Sí, alguien dentro del hogar / 3. Ambas
# 4. No conoce / 9. No sabe
names(casen_santiago) # Detectar columnas de interés (2 a 12)
casen_santiago[,c(2:12)] # Observar columnas de interés
# ---- Recodificación sistemática variables de módulo "r"
# "mutuate_at" y "pipe" de "tidyverse" permite aplicar instrucciones encadenadas
# sobre varias variables
# Primero, se codifican como numérica todas las variables.
# Segundo, se recodifican sus valores dejando como 2 los valores "no" conoce/sabe
# Tercero, se eliminan todos los casos con NA dejando sólo a respondientes efectivos (jefes de hogar)
df2 <- casen_santiago %>%
mutate_at(vars(2:12), ~as.numeric(.)) %>%
mutate_at(vars(2:12), funs(car::recode(. ,"1:3=1;4:9=2"))) %>%
drop_na()
View(df2)
# ---- Reducir dimensionalidad calculando variables a nivel comuna.
# El sentido del código se aprecia analizando la primera línea del 'summarise'
# Esto todavía se podría automatizar más, pero implicaría programación funcional (¿otro curso?).
# Dimensionalidad se reduce, calculando cada variable como proporción de categoría de referencia
comunas <- df2 %>%
group_by(comunaf) %>%
summarise(enfermos = sum(cuidado_enfermos == "1")/sum(cuidado_enfermos),
dependientes = sum(ciudado_dependientes == "1")/sum(ciudado_dependientes),
vehiculo = sum(vehiculo == "1")/sum(vehiculo),
dinero = sum(dinero == "1")/sum(dinero),
tramites = sum(tramites == "1")/sum(tramites),
tecnologias = sum(tecnologias == "1")/sum(tecnologias),
reparaciones_hogar = sum(reparaciones_hogar == "1")/sum(reparaciones_hogar),
trabajo = sum(trabajo == "1")/sum(trabajo),
consejos = sum(consejos == "1")/sum(consejos),
idiomas = sum(idiomas == "1")/sum(idiomas),
estudios = sum(estudios == "1")/sum(estudios))
View(comunas)
# ---- 3. ANÁLISIS DE CONGLOMERADOS - MÉTODO JERÁRQUICO ----
#Se usará la distancia euclidea: hay más distancias (ver ?dist)
#Se usarán variables no estandarizadas pues ya están como % (columnas 2:12)
# Cálculo de distancias (euclídea al cuadrado) con todas las variables incluídas
d <- dist(comunas[c(2:12)])^2 # distancia euclídea al cuadrado (^2)
# Error posible (teórico): no tenemos una predefinición de por qué importa cada variable
# Mostrar matriz de distancia
print(d,digits=1)
## Creación del MODELO JERARQUICO: "hclust" --> Hierarquical Clustering
# hay más algoritmos: ver ?hclust -> centroid, single, ward.D, etc.
# Se crea un modelo indicando matriz de distancias y algoritmo de clasificación.
hc <- hclust(d, method= "ward.D") # hc = 'hirarchical clustering' (algoritmo aglomerativo)
# método de clasificación: "distancia de Ward"
# Resultado se guarda como objeto 'lista' en entorno
# RESULTADO 1: historial de conglomeración
historial <- data.frame(hc[2:1]) # extracción historial de conglomeración
write.csv2(historial, file ="resultados/5-historial_hc.csv")
# Salto de mayor relevancia parece estar en solución de 3
# Elementos negativos son casos no conglomerados hasta ese paso (detección de atípicos).
View(historial)
# RESULTADO 2: dendograma
plot(hc, labels=comunas$comunaf, main = "Dendograma método jerárquico",
xlab = "Comuna",
ylab = "Distancia")
# dendograma con grupos marcados
rect.hclust (hc, k=3, border="red")
# RESULTADO 3: extraer conglomerado de pertenencia
#Para extraer conglomerado de pertenencia
pertenencia_hc <- cutree(hc, k=3) #Corte de grupos "k"
# Tabla de cantidad de casos por conglomerado
table(pertenencia_hc)
# Agregar solución de 3 conglomerados como variable de clasificación en base
comunas <- mutate(comunas, hc_3 = pertenencia_hc)
names(comunas)
View(comunas)
## RESULTADO 4: perfiles variables conglomeración según comunas (medias)
hc <- comunas %>%
group_by(hc_3) %>%
summarise(enfermos = mean(enfermos),
dependientes = mean(dependientes),
vehiculo = mean(vehiculo),
dinero = mean(dinero),
tramites = mean(tramites),
tecnologias = mean(tecnologias),
reparaciones_hogar = mean(reparaciones_hogar),
trabajo = mean(trabajo),
consejos = mean(consejos),
idiomas = mean(idiomas),
estudios = mean(estudios))
# imprimir tabla de caracterización de variables
write.csv2(hc, file = "resultados/5-medias-variables-conglomeración-j.csv")
#Remover todo excepto "comunas" del entorno
# ---- 4. ANÁLISIS DE CONGLOMERADOS - MÉTODO NO JERÁRQUICO ----
## Creación del MODELO NO JERARQUICO:
#Algoritmo K-Means, es muy utilizado, hay otros
# nstart= escoge el mejor punto de partida(aleat)
#         *poner num elevado
# centers= cantidad de conglomerados k
# iter.max= iteraciones/ pasos
km<-kmeans(comunas[2:12], centers=3, iter.max = 10, nstart = 200)
#Ver todos los resultados
km
km$iter #cantidad de interaciones
km$size #tamaño conglomerados
km$centers #centros conglomerados finales
km$cluster #conglomerado de pertenencia por caso
pertenencia_nh <-cbind(comunas[1], km[1]) #tabla con conglomerad de pertencia y comunas
View(pertenencia_nh)
#Agregar solución no jerárquica como variable de clasificación.
comunas <- mutate(comunas, km_3 = km$cluster)
# Variables de conglomeración en modelo no jerárquico
nh <- comunas %>%
group_by(km_3) %>%
summarise(enfermos = mean(enfermos),
dependientes = mean(dependientes),
vehiculo = mean(vehiculo),
dinero = mean(dinero),
tramites = mean(tramites),
tecnologias = mean(tecnologias),
reparaciones_hogar = mean(reparaciones_hogar),
trabajo = mean(trabajo),
consejos = mean(consejos),
idiomas = mean(idiomas),
estudios = mean(estudios))
View(nh)
# Exportar resultados a planilla
write.csv2(nh, file = "resultados/5-medias-variables-conglomeración-nj.csv")
# ----- GUARDAR BASE DE DATOS CON VARIABLES DE CONGLOMERACIÓN
saveRDS(comunas, file = "datos/5-cluster_comunas_casen.rds")
gitcreds::gitcreds_set()
gitcreds::gitcreds_set()
pacman::p_load(readxl, haven, tidyverse)
#Cargar base de datos SIMCE octavo por establecimiento
datos <- read_excel("datos/3-simce2m2017_rbd_publica_final.xlsx")
# Sobreescribimos seleccionando variables de interés:
# promedio puntaje lenguaje, gse, rol en base datos (ID) y zona.
datos <- select(datos, lenguaje=prom_lect2m_rbd, gse=cod_grupo, llave=rbd,
zona=cod_rural_rbd)
#Cargar base de datos SIMCE indicadores promedio desarrollo personal por establecimiento
datos2 <- read_excel("datos/3-idps2m2017_rbd_final.xlsx")
datos2 <- select(datos2, llave = rbd, region = cod_reg_rbd, comuna = cod_com_rbd, dependencia = cod_depe2)
#Cargar base de datos SIMCE por estudiante
datos3 <- read_spss("datos/3-simce nivel estudiante.sav")
#Seleccionar variables a fusionar, rbd (llave), la media de "puedo hacer las tareas y trabajos difíciles" (cest_p0_01)
#                      la media de "puntaje matemáticas" (ptje_mate2m_alu)
datos3 <- select(datos3, llave = rbd, matematicas =  ptje_mate2m_alu, dificiles = "cest_p01_01")
datos_A <- left_join(datos, datos2)
datos_A <- left_join(datos, datos2, by = "llave")
#inner_join mantiene sólo los casos efectivamente compartidos
datos_B <- inner_join(datos, datos2)
datos_B <- inner_join(datos, datos2, by = "llave")
colegio <- datos3 %>%
group_by(llave) %>%
summarize(media_mates = mean(matematicas, na.rm = T),
media_dificiles = mean(dificiles, na.rm = T))
#Dejar atributos de llave igual a las otras bases de datos (numeric y no atomic)
colegio$llave <- as.numeric(colegio$llave)
simce2017_colegio <- left_join(datos_A, colegio)
saveRDS(simce2017_colegio, file = "datos/3-simce2017colegio.rds")
gitcreds::gitcreds_set()
# Cargar base en formato R (.rds)
datos <- readRDS("datos/4-PNUD_2015.rds")
# Seleccionar variables de interés
PNUD <- select(datos, cambios, conflictos, manifestaciones, involucramiento, edad, NSE)
# Evaluar instalación y/o carga de paquetes
pacman::p_load(ca, haven, dplyr, ggplot2)
# Seleccionar variables de interés
PNUD <- select(datos, cambios, conflictos, manifestaciones, involucramiento, edad, NSE)
summary(PNUD)
PNUD$cambios<-factor(PNUD$cambios,levels=c(1,2,3),labels=c("Radicales","Graduales","Sin"))
PNUD$conflictos<-factor(PNUD$conflictos,levels=c(1,2),labels=c("Mostrarlos","Evitarlos"))
PNUD$manifestaciones<-factor(PNUD$manifestaciones,levels=c(1,2,3),labels=c("Positivas","Negativas", "Neutras"))
PNUD$involucramiento<-factor(PNUD$involucramiento,levels=c(1,2,3,4,5),
labels=c("Retraídos","Observadores","Ritualistas",
"Comprometidos/Involucrados","Colectivistas"))
PNUD$edad<-factor(PNUD$edad,levels=c(1,2,3),labels=c("Jóvenes","Adultos","Adultos mayores"))
PNUD$NSE<-factor(PNUD$NSE,levels=c(1,2,3,4),labels=c("ABC1","C2","C3","D y E"))
summary(PNUD)
library(summarytools)
dfSummary(PNUD)
mjca(PNUD)
summary(mjca(PNUD))
#Luego para generar el mapa percepctual ejecutamos el comando "plot"
plot(mjca(PNUD))
# Guardar tabla de resumen como objeto
resultados <- summary(mjca(PNUD)) # Observar lista de elementos en entorno
# Exportar tabla como archivo de planilla CSV hacia carpeta "resultados" del proyecto
write.csv2(resultados$columns, file = "resultados/4-resultados_acm.csv")
# Creamos un objeto del ACM y creamos los nombres de sus categorías para hacer una base de datos con las coordenadas
mca <- mjca(PNUD)
cats <- apply(PNUD, 2, function(x) nlevels(as.factor(x)))
mca_df <- data.frame(mca$colcoord, Variable = rep(names(cats), cats))
rownames(mca_df) = mca$levelnames
p<- ggplot(data = mca_df, aes(x = X1, y = X2, label = rownames(mca_df))) +
geom_hline(yintercept = 0, colour = "gray70") +
geom_vline(xintercept = 0, colour = "gray70") +
geom_text(aes(colour = Variable), size=5, hjust = 0, nudge_y = 0.06) +
geom_point(aes(x = X1, y = X2)) +
theme(axis.text.x=element_text(size=7), axis.text.y=element_text(size=7))+
theme_bw()
p
p + guides(col=FALSE) + geom_point(aes(x = X1, y = X2), shape = 16, size = 2) + geom_text(aes(colour = Variable), size=5, hjust = 0, nudge_y = 0.06) +xlim(-3,3) + ylim(-3,3) + xlab("D1   47,8%") + ylab("D2   8,6%")
p + guides(col="none") + geom_point(aes(x = X1, y = X2), shape = 16, size = 2) + geom_text(aes(colour = Variable), size=5, hjust = 0, nudge_y = 0.06) +xlim(-3,3) + ylim(-3,3) + xlab("D1   47,8%") + ylab("D2   8,6%")
gitcreds::gitcreds_set()
# Evaluar instalación y/o carga de paquetes
pacman::p_load(tidyverse, haven, car, labelled)
# ---- Cargar base de Casen recortada
casen_santiago <- readRDS("datos/5-casen-santiago.rds")
# Ver tipo de objeto y categorías de variable comuna
class(casen_santiago$comuna)
table(casen_santiago$comuna)
casen_santiago <- mutate(casen_santiago,
comunaf = labelled::to_character(casen_santiago$comuna,
levels = "labels",
drop_unused_labels = T))
# Elminamos etiqueta de variable
var_label(casen_santiago$comunaf) <- NULL
# Verificamos tabla con etiquetas
table(casen_santiago$comunaf)
# Recodificación módulo "r7" CASEN
# sección R: Identidades, redes y participación
# módulo de preguntas r7: ¿Alguien en su hogar, conoce a una persona que...?
# 1. Sí, alguien fuera del hogar / 2. Sí, alguien dentro del hogar / 3. Ambas
# 4. No conoce / 9. No sabe
names(casen_santiago) # Detectar columnas de interés (2 a 12)
casen_santiago[,c(2:12)] # Observar columnas de interés
df2 <- casen_santiago %>%
mutate_at(vars(2:12), ~as.numeric(.)) %>%
mutate_at(vars(2:12), funs(car::recode(. ,"1:3=1;4:9=2"))) %>%
drop_na()
View(df2)
comunas <- df2 %>%
group_by(comunaf) %>%
summarise(enfermos = sum(cuidado_enfermos == "1")/sum(cuidado_enfermos),
dependientes = sum(ciudado_dependientes == "1")/sum(ciudado_dependientes),
vehiculo = sum(vehiculo == "1")/sum(vehiculo),
dinero = sum(dinero == "1")/sum(dinero),
tramites = sum(tramites == "1")/sum(tramites),
tecnologias = sum(tecnologias == "1")/sum(tecnologias),
reparaciones_hogar = sum(reparaciones_hogar == "1")/sum(reparaciones_hogar),
trabajo = sum(trabajo == "1")/sum(trabajo),
consejos = sum(consejos == "1")/sum(consejos),
idiomas = sum(idiomas == "1")/sum(idiomas),
estudios = sum(estudios == "1")/sum(estudios))
View(comunas)
# Cálculo de distancias (euclídea al cuadrado) con todas las variables incluídas
d <- dist(comunas[c(2:12)])^2 # distancia euclídea al cuadrado (^2)
# Mostrar matriz de distancia
print(d,digits=1)
hc <- hclust(d, method= "ward.D") # hc = 'hirarchical clustering' (algoritmo aglomerativo)
# RESULTADO 1: historial de conglomeración
historial <- data.frame(hc[2:1]) # extracción historial de conglomeración
write.csv2(historial, file ="resultados/5-historial_hc.csv")
# Salto de mayor relevancia parece estar en solución de 3
# Elementos negativos son casos no conglomerados hasta ese paso (detección de atípicos).
View(historial)
plot(hc, labels=comunas$comunaf, main = "Dendograma método jerárquico",
xlab = "Comuna",
ylab = "Distancia")
# dendograma con grupos marcados
rect.hclust (hc, k=3, border="red")
#Para extraer conglomerado de pertenencia
pertenencia_hc <- cutree(hc, k=3) #Corte de grupos "k"
# Tabla de cantidad de casos por conglomerado
table(pertenencia_hc)
# Agregar solución de 3 conglomerados como variable de clasificación en base
comunas <- mutate(comunas, hc_3 = pertenencia_hc)
names(comunas)
View(comunas)
## RESULTADO 4: perfiles variables conglomeración según comunas (medias)
hc <- comunas %>%
group_by(hc_3) %>%
summarise(enfermos = mean(enfermos),
dependientes = mean(dependientes),
vehiculo = mean(vehiculo),
dinero = mean(dinero),
tramites = mean(tramites),
tecnologias = mean(tecnologias),
reparaciones_hogar = mean(reparaciones_hogar),
trabajo = mean(trabajo),
consejos = mean(consejos),
idiomas = mean(idiomas),
estudios = mean(estudios))
View(hc)
# imprimir tabla de caracterización de variables
write.csv2(hc, file = "resultados/5-medias-variables-conglomeración-j.csv")
km<-kmeans(comunas[2:12], centers=3, iter.max = 10, nstart = 200)
#Ver todos los resultados
km
km$iter #cantidad de interaciones
km$size #tamaño conglomerados
km$centers #centros conglomerados finales
pertenencia_nh <-cbind(comunas[1], km[1]) #tabla con conglomerad de pertencia y comunas
View(pertenencia_nh)
#Agregar solución no jerárquica como variable de clasificación.
comunas <- mutate(comunas, km_3 = km$cluster)
# Variables de conglomeración en modelo no jerárquico
nh <- comunas %>%
group_by(km_3) %>%
summarise(enfermos = mean(enfermos),
dependientes = mean(dependientes),
vehiculo = mean(vehiculo),
dinero = mean(dinero),
tramites = mean(tramites),
tecnologias = mean(tecnologias),
reparaciones_hogar = mean(reparaciones_hogar),
trabajo = mean(trabajo),
consejos = mean(consejos),
idiomas = mean(idiomas),
estudios = mean(estudios))
View(nh)
# Exportar resultados a planilla
write.csv2(nh, file = "resultados/5-medias-variables-conglomeración-nj.csv")
saveRDS(comunas, file = "datos/cluster_comunas_casen.rds")
saveRDS(comunas, file = "datos/5-cluster_comunas_casen.rds")
gitcreds::gitcreds_set()
